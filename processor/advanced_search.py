#!/usr/bin/env python3
import argparse
import json
from datetime import datetime, timedelta
from sentence_transformers import SentenceTransformer
from qdrant_client import QdrantClient
from qdrant_client.models import Filter, FieldCondition, MatchValue, Range

class AdvancedLogSearchClient:
    def __init__(self, host="localhost", port=6333):
        self.client = QdrantClient(host=host, port=port)
        self.model = SentenceTransformer('all-MiniLM-L6-v2')
    
    def search_logs(self, query, collection_name="universal-logs", 
                   limit=10, min_score=0.3, level=None, source=None, hours=None):
        """–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ —Å —Ñ–∏–ª—å—Ç—Ä–∞–º–∏ –ø–æ –≤—Ä–µ–º–µ–Ω–∏"""
        
        # –°—Ç—Ä–æ–∏–º —Ñ–∏–ª—å—Ç—Ä—ã
        filter_conditions = []
        
        if level:
            filter_conditions.append(
                FieldCondition(key="level", match=MatchValue(value=level))
            )
        
        if source:
            filter_conditions.append(
                FieldCondition(key="source", match=MatchValue(value=source))
            )
        
        if hours:
            time_threshold = (datetime.now() - timedelta(hours=hours)).isoformat()
            filter_conditions.append(
                FieldCondition(
                    key="timestamp",
                    range=Range(gte=time_threshold)
                )
            )
        
        search_filter = Filter(must=filter_conditions) if filter_conditions else None
        
        # –ü–æ–∏—Å–∫
        query_vector = self.model.encode(query).tolist()
        results = self.client.search(
            collection_name=collection_name,
            query_vector=query_vector,
            query_filter=search_filter,
            limit=limit,
            with_payload=True,
            score_threshold=min_score
        )
        
        return results
    
    def get_collection_stats(self, collection_name):
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫–æ–ª–ª–µ–∫—Ü–∏–∏"""
        try:
            collection_info = self.client.get_collection(collection_name)
            count_result = self.client.count(collection_name)
            
            return {
                "collection": collection_name,
                "vectors_count": count_result.count,
                "status": collection_info.status,
                "vectors_config": collection_info.config.params.vectors
            }
        except Exception as e:
            return {"error": str(e)}
    
    def find_similar_logs(self, log_id, collection_name="universal-logs", limit=5):
        """–ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –ª–æ–≥–æ–≤ –ø–æ ID"""
        try:
            # –ü–æ–ª—É—á–∞–µ–º –≤–µ–∫—Ç–æ—Ä –ø–æ ID
            points = self.client.retrieve(
                collection_name=collection_name,
                ids=[log_id],
                with_vectors=True
            )
            
            if not points:
                return []
            
            point = points[0]
            similar_results = self.client.search(
                collection_name=collection_name,
                query_vector=point.vector,
                limit=limit + 1,  # +1 –ø–æ—Ç–æ–º—É —á—Ç–æ –Ω–∞–π–¥–µ—Ç —Å–∞–º —Å–µ–±—è
                with_payload=True
            )
            
            # –ò—Å–∫–ª—é—á–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π –ª–æ–≥ –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            return [r for r in similar_results if r.id != log_id]
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
            return []
    
    def export_results(self, results, filename="search_results.json"):
        """–≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ JSON"""
        export_data = []
        for result in results:
            export_data.append({
                "id": result.id,
                "score": result.score,
                "payload": result.payload
            })
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(export_data, f, ensure_ascii=False, indent=2)
        
        print(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –≤ {filename}")

def main():
    parser = argparse.ArgumentParser(description="Qdrant Log Search Client")
    parser.add_argument("query", nargs="?", help="–ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å")
    parser.add_argument("--collection", "-c", default="universal-logs", 
                       help="–ò–º—è –∫–æ–ª–ª–µ–∫—Ü–∏–∏")
    parser.add_argument("--limit", "-l", type=int, default=10, 
                       help="–õ–∏–º–∏—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
    parser.add_argument("--level", choices=["ERROR", "WARN", "INFO", "DEBUG"],
                       help="–§–∏–ª—å—Ç—Ä –ø–æ —É—Ä–æ–≤–Ω—é")
    parser.add_argument("--source", help="–§–∏–ª—å—Ç—Ä –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫—É")
    parser.add_argument("--hours", type=int, help="–§–∏–ª—å—Ç—Ä –ø–æ –≤—Ä–µ–º–µ–Ω–∏ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ N —á–∞—Å–æ–≤)")
    parser.add_argument("--min-score", type=float, default=0.3,
                       help="–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Å—Ö–æ–∂–µ—Å—Ç—å")
    parser.add_argument("--stats", action="store_true", 
                       help="–ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∫–æ–ª–ª–µ–∫—Ü–∏–∏")
    parser.add_argument("--similar-to", type=int, 
                       help="–ù–∞–π—Ç–∏ –ø–æ—Ö–æ–∂–∏–µ –Ω–∞ –ª–æ–≥ —Å —É–∫–∞–∑–∞–Ω–Ω—ã–º ID")
    parser.add_argument("--export", help="–≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ —Ñ–∞–π–ª")
    
    args = parser.parse_args()
    client = AdvancedLogSearchClient()
    
    if args.stats:
        # –ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        stats = client.get_collection_stats(args.collection)
        print("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫–æ–ª–ª–µ–∫—Ü–∏–∏:")
        print(json.dumps(stats, indent=2, ensure_ascii=False))
        return
    
    if args.similar_to:
        # –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –ª–æ–≥–æ–≤
        results = client.find_similar_logs(args.similar_to, args.collection, args.limit)
        print(f"üîç –õ–æ–≥–∏ –ø–æ—Ö–æ–∂–∏–µ –Ω–∞ ID {args.similar_to}:")
        for i, result in enumerate(results, 1):
            print(f"{i}. [{result.payload.get('level')}] {result.payload.get('message')}")
            print(f"   –°—Ö–æ–∂–µ—Å—Ç—å: {result.score:.3f}, ID: {result.id}\n")
        return
    
    if not args.query:
        print("‚ùå –£–∫–∞–∂–∏—Ç–µ –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å")
        parser.print_help()
        return
    
    # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫
    results = client.search_logs(
        query=args.query,
        collection_name=args.collection,
        limit=args.limit,
        min_score=args.min_score,
        level=args.level,
        source=args.source,
        hours=args.hours
    )
    
    # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    print(f"\nüîç –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞: '{args.query}'")
    print(f"üìÅ –ö–æ–ª–ª–µ–∫—Ü–∏—è: {args.collection}")
    print(f"üìä –ù–∞–π–¥–µ–Ω–æ: {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
    print("=" * 80)
    
    for i, result in enumerate(results, 1):
        payload = result.payload
        print(f"{i}. [{payload.get('level', 'UNKNOWN')}] {payload.get('message')}")
        print(f"   üìç {payload.get('source', 'unknown')} | üïí {payload.get('timestamp', 'N/A')}")
        print(f"   üéØ –°—Ö–æ–∂–µ—Å—Ç—å: {result.score:.3f} | üÜî {result.id}")
        print("-" * 60)
    
    # –≠–∫—Å–ø–æ—Ä—Ç –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    if args.export and results:
        client.export_results(results, args.export)

if __name__ == "__main__":
    main()
